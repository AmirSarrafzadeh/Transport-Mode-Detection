{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"005_CNN_Model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"code","metadata":{"id":"KPpdD3JqqFJ4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625241681062,"user_tz":-120,"elapsed":454,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}},"outputId":"5349a977-3555-4b47-8e6e-d2aa86617299"},"source":["# Mount The Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7Z4iBvkGqG_g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625241681429,"user_tz":-120,"elapsed":4,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}},"outputId":"e10cd91e-01eb-4fc6-ca84-ac0e140650f6"},"source":["# Import Libraries\n","import os\n","import glob\n","import numpy as np\n","import pandas as pd\n","import time \n","import datetime\n","import pickle\n","import random\n","import math\n","from collections import Counter\n","import statistics \n","from statistics import mode\n","pd.options.mode.chained_assignment = None\n","print(\"Libraries Are Imported\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Libraries Are Imported\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wjk2T3wUqHE-","executionInfo":{"status":"ok","timestamp":1625241681429,"user_tz":-120,"elapsed":1,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}}},"source":["# Define Path of Data\n","path = '/content/gdrive/My Drive/Thesis/Pickle'\n","os.chdir(path)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSh1DtYiRC8U","executionInfo":{"status":"ok","timestamp":1625241683837,"user_tz":-120,"elapsed":2409,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}}},"source":["# Read The Labeled Data\n","DF = '004_Preprocessed_Data.pickle'\n","infile = open(DF,'rb')\n","df = pickle.load(infile)\n","infile.close()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"GczNua379v7q","executionInfo":{"status":"ok","timestamp":1625241686829,"user_tz":-120,"elapsed":2993,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}}},"source":["# Replace Names with Characters\n","df.replace('bike', 'p', inplace=True)\n","df.replace('bus', 'b', inplace=True)\n","df.replace('car', 'c', inplace=True)\n","df.replace('train', 't', inplace=True)\n","df.replace('walk', 'w', inplace=True)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"qdiWwHKR9wAV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625241691913,"user_tz":-120,"elapsed":5093,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}},"outputId":"5ddccb87-86c3-49c7-967c-f5766080dbe8"},"source":["# Split All Data to Train and Test Set Randomly\n","User_List = df['User'].unique().tolist()\n","!pip install mpu\n","\n","import mpu\n","random.seed(29)\n","list_one = User_List\n","\n","list_one, list_two = mpu.consistent_shuffle(list_one,list_one)\n","train_user = list_one[:45]\n","test_user = list_one[45:]\n","\n","Train_Data = df[df['User'].isin(train_user)]\n","Test_Data = df[df['User'].isin(test_user)]\n","\n","Train_data = []\n","for i, g in Train_Data.groupby(['Trip','User']):\n","  Train_data.append(g)\n","\n","Test_data = []\n","for l, m in Test_Data.groupby(['Trip','User']):\n","  Test_data.append(m)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mpu in /usr/local/lib/python3.7/dist-packages (0.23.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oMN4HtHR-MI2","executionInfo":{"status":"ok","timestamp":1625241696786,"user_tz":-120,"elapsed":4875,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}}},"source":["# Define Extra Columns and Drop them\n","extra_columns = ['Latitude', 'Longitude', 'Altitude', 'Date', 'User', 'TS', 'Trip', 'Mode', 'Distance', 'DT', 'Bearing', 'Cum_Distance']\n","\n","Train_Y_t = []\n","for df in Train_data:      \n","    Train_Y_t.append(df['Mode'].values)\n","    df.drop(columns=extra_columns, inplace=True)\n","\n","Test_Y_t = []\n","for df in Test_data:      \n","    Test_Y_t.append(df['Mode'].values)\n","    df.drop(columns=extra_columns, inplace=True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ta-uapF_-MLu","executionInfo":{"status":"ok","timestamp":1625241696787,"user_tz":-120,"elapsed":8,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}}},"source":["# Normalize Both Train and Test Datasets\n","Train_Normalize = []\n","for df in Train_data:      \n","    Train_Normalize.append(df.values)\n","\n","Test_Normalize = []\n","for df in Test_data:      \n","    Test_Normalize.append(df.values)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"_tMRMnwf-MPX","executionInfo":{"status":"ok","timestamp":1625241696788,"user_tz":-120,"elapsed":8,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}}},"source":["# Define Maximum and Minimum Trip Sizes\n","max_trip_size = 200\n","min_trip_size = 60"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"_jmsjKPk-MSm","executionInfo":{"status":"ok","timestamp":1625241696788,"user_tz":-120,"elapsed":8,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}}},"source":["# Break the Trips to Windows - Add Padding to Windows\n","def break_trip(trip, trip_Y, max_trip_size):\n","    length = max_trip_size\n","    jump = length\n","    split = [trip[i:i+length] for i in range(0,len(trip),jump)][:-1]+[trip[-length:]]\n","    split_Y = [trip_Y[i:i+length] for i in range(0,len(trip_Y),jump)][:-1]+[trip_Y[-length:]] \n","    return split, split_Y\n","\n","def padd_trip(trip, trip_Y, max_trip_size):\n","    trip_padded = np.pad(trip, ((0, max_trip_size-trip.shape[0]), (0, 0)), 'constant')\n","    trip_padded_Y = np.pad(trip_Y, (0, max_trip_size-trip.shape[0]), 'constant', constant_values=(0,0))\n","    return trip_padded, trip_padded_Y\n","\n","Train_X = []\n","Train_Y = []\n","for i, trip in enumerate(Train_Normalize):\n","    size_trip = trip.shape[0]\n","    if  size_trip <= min_trip_size:   \n","        continue\n","    \n","    if size_trip > max_trip_size:\n","        trip_breaks, trip_breaks_Y = break_trip(trip, Train_Y_t[i], max_trip_size)\n","        Train_X.extend(trip_breaks)\n","        Train_Y.extend(trip_breaks_Y)            \n","        \n","    if size_trip <= max_trip_size and size_trip > min_trip_size:\n","        trip_pad, trip_pad_Y = padd_trip(trip, Train_Y_t[i], max_trip_size)\n","        Train_X.append(trip_pad)\n","        Train_Y.append(Counter(Train_Y_t[i].flat).most_common(1)[0][0])   \n","\n","Test_X = []\n","Test_Y = []\n","for i, trip in enumerate(Test_Normalize):\n","    size_trip = trip.shape[0]\n","    if  size_trip <= min_trip_size:   \n","        continue\n","    \n","    if size_trip > max_trip_size:\n","        trip_breaks, trip_breaks_Y = break_trip(trip, Test_Y_t[i], max_trip_size)\n","        Test_X.extend(trip_breaks)\n","        Test_Y.extend(trip_breaks_Y)\n","         \n","    if size_trip <= max_trip_size and size_trip > min_trip_size:\n","        trip_pad, trip_pad_Y = padd_trip(trip, Test_Y_t[i], max_trip_size)\n","        Test_X.append(trip_pad)\n","        Test_Y.append(Counter(Test_Y_t[i].flat).most_common(1)[0][0])"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"7QRHUbAm9wFU","executionInfo":{"status":"ok","timestamp":1625241697344,"user_tz":-120,"elapsed":564,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}}},"source":["# Find the mode of each Single Window\n","Train_M = []\n","for i in Train_Y:\n","  if len(i) == 1:\n","    Train_M.append(i)\n","  else:\n","    lst = i.tolist()\n","    Train_M.append(max(set(lst), key=lst.count))\n","\n","Test_M = []\n","for i in Test_Y:\n","  if len(i) == 1:\n","    Test_M.append(i)\n","  else:\n","    lst = i.tolist()\n","    Test_M.append(max(set(lst), key=lst.count))\n","\n","train_Y = pd.DataFrame(Train_M,columns=['LL'])\n","test_Y = pd.DataFrame(Test_M,columns=['LL'])"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"V71ORtmSP0j0","executionInfo":{"status":"ok","timestamp":1625241697344,"user_tz":-120,"elapsed":7,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}}},"source":["# Replace Characters with Names in Train Dataset\n","train_Y.replace('p', 'bike', inplace=True)\n","train_Y.replace('b', 'bus', inplace=True)\n","train_Y.replace('c', 'car', inplace=True)\n","train_Y.replace('t', 'train', inplace=True)\n","train_Y.replace('w', 'walk', inplace=True)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"CSpbtnoUQIdA","executionInfo":{"status":"ok","timestamp":1625241697345,"user_tz":-120,"elapsed":8,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}}},"source":["# Replace Characters with Names in Test Dataset\n","test_Y.replace('p', 'bike', inplace=True)\n","test_Y.replace('b', 'bus', inplace=True)\n","test_Y.replace('c', 'car', inplace=True)\n","test_Y.replace('t', 'train', inplace=True)\n","test_Y.replace('w', 'walk', inplace=True)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"vl79bOKLQIfF","executionInfo":{"status":"ok","timestamp":1625241697345,"user_tz":-120,"elapsed":7,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}}},"source":["# Save all Data in a Dictionary\n","data_dict = dict()\n","data_dict['Train_X'] = Train_X\n","data_dict['Train_Y'] = train_Y\n","data_dict['Test_X'] = Test_X\n","data_dict['Test_Y'] = test_Y"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"4IXS_wBNP0ls","executionInfo":{"status":"ok","timestamp":1625241697345,"user_tz":-120,"elapsed":7,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}}},"source":["# Define Train_X, Test_X. train_Y, and test_Y\n","Train_X = np.asarray(data_dict['Train_X']).astype('float32')\n","train_Y = np.asarray(data_dict['Train_Y'])\n","Test_X = np.asarray(data_dict['Test_X']).astype('float32')\n","test_Y = np.asarray(data_dict['Test_Y'])"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"HxOwCAyJQZL8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625241697345,"user_tz":-120,"elapsed":7,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}},"outputId":"f53895eb-6867-4479-a615-438c552fc84b"},"source":["# Apply One Hot Encoding To Train_Y and Test_Y\n","from sklearn.preprocessing import OneHotEncoder\n","enc = OneHotEncoder(handle_unknown='ignore')\n","Train_Y = enc.fit_transform(train_Y.reshape(-1, 1)).toarray()\n","print(Train_X.shape)\n","print(Train_Y.shape)\n","Test_Y = enc.fit_transform(test_Y.reshape(-1, 1)).toarray()\n","print(Test_X.shape)\n","print(Test_Y.shape)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["(22348, 200, 3)\n","(22348, 5)\n","(4480, 200, 3)\n","(4480, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pwwu1ZnOQZOS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625241697347,"user_tz":-120,"elapsed":6,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}},"outputId":"53e6b625-d63d-4b7c-e96d-d0ac400180bc"},"source":["# Define Number of Features and Number of Classes\n","num_features = Train_X.shape[-1]\n","print(num_features)\n","Modes = enc.categories_\n","NoClass = len(Modes[0])\n","print(NoClass)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["3\n","5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4ErNXup6QZTj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625241699899,"user_tz":-120,"elapsed":2557,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}},"outputId":"331121e6-1caf-421b-b00e-98136533a823"},"source":["# Import Deep Learning Libraries\n","import tensorflow as tf\n","tf.random.set_seed(42)\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Conv1D, Flatten, MaxPooling1D, BatchNormalization, Activation, Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n","from tensorflow.keras import regularizers\n","from sklearn.model_selection import KFold\n","from sklearn import metrics\n","from scipy.stats import zscore\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","\n","tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n","sess = print(tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True)))\n","\n","start_time = time.clock()\n","np.random.seed(7)\n","random.seed(7)\n","\n","trip_size = Train_X.shape[-2]\n","trip_size"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Device mapping:\n","/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","\n","Device mapping:\n","/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","\n","<tensorflow.python.client.session.Session object at 0x7fd204c1fd50>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["200"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"805Zcx5KxK-d","executionInfo":{"status":"ok","timestamp":1625241699899,"user_tz":-120,"elapsed":2,"user":{"displayName":"Amir sarrafzadeh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgF4jrw5H5CJhyyB1ApCoS9hQnBVQeXVXHtH8_pLQ=s64","userId":"14181695720010602226"}}},"source":["# Define Kernel Size, Maxpooling Size, Stride\n","kernel = 16\n","pool = 4\n","stride = 1\n","Drop_Out = 0.6"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"ciZH8pgTKu4J","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d543c12b-832f-4e14-aa23-87b4e71d91ec"},"source":["# Structure of Model and Compile\n","model = Sequential()\n","model.add(Conv1D(64, kernel, strides=stride, padding='same', dilation_rate = 1, input_shape=(trip_size, num_features)))\n","model.add(Activation(\"relu\"))\n","model.add(Conv1D(64, kernel, strides=stride, padding='same', dilation_rate = 1))\n","model.add(BatchNormalization())\n","model.add(Activation(\"relu\"))\n","model.add(MaxPooling1D(pool_size=pool))\n","\n","model.add(Dropout(Drop_Out))\n","\n","model.add(Conv1D(128, kernel, strides=stride, padding='same', dilation_rate = 1))\n","model.add(Activation(\"relu\"))\n","model.add(Conv1D(128, kernel, strides=stride, padding='same', dilation_rate = 1))\n","model.add(BatchNormalization())\n","model.add(Activation(\"relu\"))\n","model.add(MaxPooling1D(pool_size=pool))\n","\n","model.add(Dropout(Drop_Out))\n","\n","model.add(Conv1D(256, kernel, strides=stride, padding='same', dilation_rate = 1))\n","model.add(Activation(\"relu\"))\n","model.add(Conv1D(256, kernel, strides=stride, padding='same', dilation_rate = 1))\n","model.add(BatchNormalization())\n","model.add(Activation(\"relu\"))\n","model.add(MaxPooling1D(pool_size=pool))\n","\n","model.add(Flatten())\n","\n","model.add(Dropout(Drop_Out))\n","\n","model.add(Dense(2048))\n","model.add(Activation(\"relu\"))\n","\n","model.add(Dropout(Drop_Out))\n","\n","model.add(Dense(1024))\n","model.add(Activation(\"relu\"))\n","\n","model.add(Dense(NoClass, activation='softmax'))\n","\n","EPOCHS = 100\n","def scheduler(epoch, lr):\n","    if epoch % EPOCHS == 0 and epoch != 0:\n","        print(\"[INFO] lr is  ... \", lr/10)                \n","        return lr/10\n","    else:\n","        return lr\n","\n","# optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","optimizer = RMSprop(lr=0.001)\n","# optimizer = SGD(lr=0.0001, momentum=0.9, decay=1e-4, nesterov=True)\n","\n","callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","hist = model.fit(Train_X, Train_Y, epochs=500, batch_size=64, validation_data=(Test_X, Test_Y), callbacks=[callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","350/350 [==============================] - 9s 15ms/step - loss: 1.2210 - accuracy: 0.5603 - val_loss: 1.1203 - val_accuracy: 0.6199\n","Epoch 2/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.8914 - accuracy: 0.7022 - val_loss: 0.7663 - val_accuracy: 0.8033\n","Epoch 3/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.8310 - accuracy: 0.7310 - val_loss: 1.0197 - val_accuracy: 0.6571\n","Epoch 4/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.8038 - accuracy: 0.7446 - val_loss: 0.7144 - val_accuracy: 0.7404\n","Epoch 5/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7992 - accuracy: 0.7470 - val_loss: 0.7322 - val_accuracy: 0.7690\n","Epoch 6/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7860 - accuracy: 0.7557 - val_loss: 1.3174 - val_accuracy: 0.6346\n","Epoch 7/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7727 - accuracy: 0.7602 - val_loss: 0.7867 - val_accuracy: 0.8190\n","Epoch 8/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7523 - accuracy: 0.7695 - val_loss: 0.7294 - val_accuracy: 0.8069\n","Epoch 9/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7455 - accuracy: 0.7725 - val_loss: 0.7833 - val_accuracy: 0.7504\n","Epoch 10/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7302 - accuracy: 0.7747 - val_loss: 0.6674 - val_accuracy: 0.8076\n","Epoch 11/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7461 - accuracy: 0.7794 - val_loss: 0.7352 - val_accuracy: 0.7891\n","Epoch 12/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7307 - accuracy: 0.7809 - val_loss: 0.7096 - val_accuracy: 0.8243\n","Epoch 13/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7264 - accuracy: 0.7851 - val_loss: 0.8343 - val_accuracy: 0.8062\n","Epoch 14/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7034 - accuracy: 0.7836 - val_loss: 0.9756 - val_accuracy: 0.6790\n","Epoch 15/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6994 - accuracy: 0.7861 - val_loss: 0.6760 - val_accuracy: 0.8022\n","Epoch 16/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6966 - accuracy: 0.7887 - val_loss: 1.2884 - val_accuracy: 0.6650\n","Epoch 17/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.8569 - accuracy: 0.7829 - val_loss: 0.5875 - val_accuracy: 0.8364\n","Epoch 18/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6965 - accuracy: 0.7870 - val_loss: 0.6207 - val_accuracy: 0.8199\n","Epoch 19/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6956 - accuracy: 0.7901 - val_loss: 0.6299 - val_accuracy: 0.8172\n","Epoch 20/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7134 - accuracy: 0.7914 - val_loss: 0.7105 - val_accuracy: 0.8286\n","Epoch 21/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7434 - accuracy: 0.7915 - val_loss: 0.6015 - val_accuracy: 0.8453\n","Epoch 22/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6797 - accuracy: 0.7955 - val_loss: 0.7078 - val_accuracy: 0.8203\n","Epoch 23/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6761 - accuracy: 0.7951 - val_loss: 0.8301 - val_accuracy: 0.7545\n","Epoch 24/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6937 - accuracy: 0.7968 - val_loss: 0.7475 - val_accuracy: 0.8498\n","Epoch 25/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6817 - accuracy: 0.7996 - val_loss: 0.5739 - val_accuracy: 0.8404\n","Epoch 26/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6975 - accuracy: 0.7999 - val_loss: 0.8599 - val_accuracy: 0.8031\n","Epoch 27/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6746 - accuracy: 0.7977 - val_loss: 0.7885 - val_accuracy: 0.7761\n","Epoch 28/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7321 - accuracy: 0.8037 - val_loss: 1.3239 - val_accuracy: 0.6281\n","Epoch 29/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7583 - accuracy: 0.7987 - val_loss: 0.6913 - val_accuracy: 0.7908\n","Epoch 30/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6491 - accuracy: 0.8042 - val_loss: 1.7198 - val_accuracy: 0.7000\n","Epoch 31/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6812 - accuracy: 0.8041 - val_loss: 0.9351 - val_accuracy: 0.7931\n","Epoch 32/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6691 - accuracy: 0.7983 - val_loss: 0.5483 - val_accuracy: 0.8473\n","Epoch 33/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7386 - accuracy: 0.7980 - val_loss: 0.6144 - val_accuracy: 0.8237\n","Epoch 34/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7396 - accuracy: 0.7962 - val_loss: 1.1048 - val_accuracy: 0.8212\n","Epoch 35/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6597 - accuracy: 0.8024 - val_loss: 0.5724 - val_accuracy: 0.8330\n","Epoch 36/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7390 - accuracy: 0.8076 - val_loss: 0.8340 - val_accuracy: 0.8145\n","Epoch 37/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6557 - accuracy: 0.8056 - val_loss: 0.8422 - val_accuracy: 0.7980\n","Epoch 38/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6798 - accuracy: 0.8045 - val_loss: 0.7156 - val_accuracy: 0.8212\n","Epoch 39/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6817 - accuracy: 0.8083 - val_loss: 0.8511 - val_accuracy: 0.7862\n","Epoch 40/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6498 - accuracy: 0.8055 - val_loss: 0.7999 - val_accuracy: 0.8263\n","Epoch 41/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6941 - accuracy: 0.8053 - val_loss: 0.6471 - val_accuracy: 0.8304\n","Epoch 42/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6613 - accuracy: 0.8052 - val_loss: 0.8250 - val_accuracy: 0.8078\n","Epoch 43/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6981 - accuracy: 0.8090 - val_loss: 0.7135 - val_accuracy: 0.8277\n","Epoch 44/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6813 - accuracy: 0.8074 - val_loss: 0.6702 - val_accuracy: 0.8297\n","Epoch 45/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6649 - accuracy: 0.8097 - val_loss: 0.7204 - val_accuracy: 0.8203\n","Epoch 46/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.8490 - accuracy: 0.8034 - val_loss: 0.6232 - val_accuracy: 0.8348\n","Epoch 47/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7734 - accuracy: 0.8079 - val_loss: 0.6423 - val_accuracy: 0.8357\n","Epoch 48/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6510 - accuracy: 0.8093 - val_loss: 0.7481 - val_accuracy: 0.8031\n","Epoch 49/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7429 - accuracy: 0.8110 - val_loss: 0.7525 - val_accuracy: 0.8460\n","Epoch 50/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6659 - accuracy: 0.8112 - val_loss: 0.6617 - val_accuracy: 0.8406\n","Epoch 51/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6550 - accuracy: 0.8096 - val_loss: 0.7196 - val_accuracy: 0.8004\n","Epoch 52/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6329 - accuracy: 0.8117 - val_loss: 0.6033 - val_accuracy: 0.8471\n","Epoch 53/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7217 - accuracy: 0.8106 - val_loss: 0.6001 - val_accuracy: 0.8319\n","Epoch 54/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7917 - accuracy: 0.8112 - val_loss: 0.7693 - val_accuracy: 0.7862\n","Epoch 55/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6987 - accuracy: 0.8096 - val_loss: 0.6011 - val_accuracy: 0.8382\n","Epoch 56/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6578 - accuracy: 0.8119 - val_loss: 0.7131 - val_accuracy: 0.8154\n","Epoch 57/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6421 - accuracy: 0.8120 - val_loss: 0.6114 - val_accuracy: 0.8558\n","Epoch 58/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7755 - accuracy: 0.8103 - val_loss: 1.0937 - val_accuracy: 0.8467\n","Epoch 59/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6625 - accuracy: 0.8100 - val_loss: 0.7392 - val_accuracy: 0.7703\n","Epoch 60/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7247 - accuracy: 0.8122 - val_loss: 0.9012 - val_accuracy: 0.8087\n","Epoch 61/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6569 - accuracy: 0.8130 - val_loss: 0.6209 - val_accuracy: 0.8462\n","Epoch 62/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6869 - accuracy: 0.8151 - val_loss: 0.6124 - val_accuracy: 0.8516\n","Epoch 63/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6412 - accuracy: 0.8144 - val_loss: 0.5862 - val_accuracy: 0.8362\n","Epoch 64/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6823 - accuracy: 0.8120 - val_loss: 0.7173 - val_accuracy: 0.7900\n","Epoch 65/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6705 - accuracy: 0.8143 - val_loss: 2.9618 - val_accuracy: 0.7696\n","Epoch 66/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7652 - accuracy: 0.8109 - val_loss: 0.6943 - val_accuracy: 0.8292\n","Epoch 67/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7075 - accuracy: 0.8121 - val_loss: 0.6131 - val_accuracy: 0.8426\n","Epoch 68/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6723 - accuracy: 0.8156 - val_loss: 0.7390 - val_accuracy: 0.8121\n","Epoch 69/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7283 - accuracy: 0.8136 - val_loss: 0.6577 - val_accuracy: 0.8234\n","Epoch 70/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6282 - accuracy: 0.8179 - val_loss: 0.5986 - val_accuracy: 0.8313\n","Epoch 71/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6624 - accuracy: 0.8123 - val_loss: 0.6224 - val_accuracy: 0.8525\n","Epoch 72/500\n","350/350 [==============================] - 5s 13ms/step - loss: 1.1608 - accuracy: 0.8144 - val_loss: 0.6617 - val_accuracy: 0.8210\n","Epoch 73/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7324 - accuracy: 0.8141 - val_loss: 0.6719 - val_accuracy: 0.8328\n","Epoch 74/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6833 - accuracy: 0.8188 - val_loss: 0.6230 - val_accuracy: 0.8379\n","Epoch 75/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6751 - accuracy: 0.8146 - val_loss: 0.6939 - val_accuracy: 0.8000\n","Epoch 76/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6518 - accuracy: 0.8172 - val_loss: 0.5929 - val_accuracy: 0.8359\n","Epoch 77/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6559 - accuracy: 0.8179 - val_loss: 0.6166 - val_accuracy: 0.8366\n","Epoch 78/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7143 - accuracy: 0.8172 - val_loss: 0.6552 - val_accuracy: 0.8301\n","Epoch 79/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6897 - accuracy: 0.8141 - val_loss: 1.4999 - val_accuracy: 0.7951\n","Epoch 80/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6349 - accuracy: 0.8153 - val_loss: 1.0982 - val_accuracy: 0.7636\n","Epoch 81/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6600 - accuracy: 0.8169 - val_loss: 0.6750 - val_accuracy: 0.8326\n","Epoch 82/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7127 - accuracy: 0.8197 - val_loss: 0.8047 - val_accuracy: 0.8152\n","Epoch 83/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7599 - accuracy: 0.8149 - val_loss: 0.7038 - val_accuracy: 0.8388\n","Epoch 84/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6835 - accuracy: 0.8203 - val_loss: 0.7715 - val_accuracy: 0.8560\n","Epoch 85/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6426 - accuracy: 0.8160 - val_loss: 0.7462 - val_accuracy: 0.8201\n","Epoch 86/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6628 - accuracy: 0.8193 - val_loss: 0.6293 - val_accuracy: 0.8317\n","Epoch 87/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7380 - accuracy: 0.8162 - val_loss: 0.8640 - val_accuracy: 0.7996\n","Epoch 88/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6305 - accuracy: 0.8180 - val_loss: 0.8106 - val_accuracy: 0.7806\n","Epoch 89/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7144 - accuracy: 0.8159 - val_loss: 0.6000 - val_accuracy: 0.8368\n","Epoch 90/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6275 - accuracy: 0.8211 - val_loss: 0.8056 - val_accuracy: 0.8228\n","Epoch 91/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6778 - accuracy: 0.8164 - val_loss: 0.7804 - val_accuracy: 0.8062\n","Epoch 92/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6810 - accuracy: 0.8190 - val_loss: 0.7372 - val_accuracy: 0.8321\n","Epoch 93/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6392 - accuracy: 0.8167 - val_loss: 0.6913 - val_accuracy: 0.8125\n","Epoch 94/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6745 - accuracy: 0.8223 - val_loss: 0.6721 - val_accuracy: 0.8230\n","Epoch 95/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7583 - accuracy: 0.8153 - val_loss: 0.6986 - val_accuracy: 0.8411\n","Epoch 96/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6899 - accuracy: 0.8152 - val_loss: 0.6377 - val_accuracy: 0.8326\n","Epoch 97/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6433 - accuracy: 0.8198 - val_loss: 0.7055 - val_accuracy: 0.8388\n","Epoch 98/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6224 - accuracy: 0.8204 - val_loss: 0.8197 - val_accuracy: 0.7888\n","Epoch 99/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7520 - accuracy: 0.8194 - val_loss: 0.8246 - val_accuracy: 0.7906\n","Epoch 100/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6256 - accuracy: 0.8213 - val_loss: 0.8130 - val_accuracy: 0.7875\n","Epoch 101/500\n","[INFO] lr is  ...  0.00010000000474974513\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6017 - accuracy: 0.8311 - val_loss: 0.6203 - val_accuracy: 0.8498\n","Epoch 102/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7051 - accuracy: 0.8357 - val_loss: 0.6368 - val_accuracy: 0.8475\n","Epoch 103/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6310 - accuracy: 0.8349 - val_loss: 0.6128 - val_accuracy: 0.8540\n","Epoch 104/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6064 - accuracy: 0.8388 - val_loss: 0.6590 - val_accuracy: 0.8504\n","Epoch 105/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5467 - accuracy: 0.8384 - val_loss: 0.6429 - val_accuracy: 0.8504\n","Epoch 106/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5498 - accuracy: 0.8401 - val_loss: 0.6390 - val_accuracy: 0.8489\n","Epoch 107/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5893 - accuracy: 0.8397 - val_loss: 0.6230 - val_accuracy: 0.8426\n","Epoch 108/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5226 - accuracy: 0.8396 - val_loss: 0.6324 - val_accuracy: 0.8480\n","Epoch 109/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6136 - accuracy: 0.8383 - val_loss: 0.6628 - val_accuracy: 0.8406\n","Epoch 110/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5362 - accuracy: 0.8396 - val_loss: 0.6409 - val_accuracy: 0.8426\n","Epoch 111/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5901 - accuracy: 0.8426 - val_loss: 0.6431 - val_accuracy: 0.8489\n","Epoch 112/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6076 - accuracy: 0.8417 - val_loss: 0.6545 - val_accuracy: 0.8404\n","Epoch 113/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5797 - accuracy: 0.8402 - val_loss: 0.6374 - val_accuracy: 0.8500\n","Epoch 114/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6061 - accuracy: 0.8422 - val_loss: 0.6932 - val_accuracy: 0.8424\n","Epoch 115/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6229 - accuracy: 0.8426 - val_loss: 0.7152 - val_accuracy: 0.8540\n","Epoch 116/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5249 - accuracy: 0.8433 - val_loss: 0.7467 - val_accuracy: 0.8429\n","Epoch 117/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6692 - accuracy: 0.8417 - val_loss: 0.6842 - val_accuracy: 0.8511\n","Epoch 118/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6569 - accuracy: 0.8446 - val_loss: 0.6647 - val_accuracy: 0.8464\n","Epoch 119/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5374 - accuracy: 0.8407 - val_loss: 0.6836 - val_accuracy: 0.8480\n","Epoch 120/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6446 - accuracy: 0.8390 - val_loss: 0.6762 - val_accuracy: 0.8511\n","Epoch 121/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.9188 - accuracy: 0.8423 - val_loss: 0.6995 - val_accuracy: 0.8538\n","Epoch 122/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.8603 - accuracy: 0.8413 - val_loss: 0.6765 - val_accuracy: 0.8518\n","Epoch 123/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5877 - accuracy: 0.8442 - val_loss: 0.6797 - val_accuracy: 0.8549\n","Epoch 124/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5417 - accuracy: 0.8433 - val_loss: 0.7539 - val_accuracy: 0.8520\n","Epoch 125/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5129 - accuracy: 0.8409 - val_loss: 0.7545 - val_accuracy: 0.8509\n","Epoch 126/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5243 - accuracy: 0.8424 - val_loss: 0.6668 - val_accuracy: 0.8388\n","Epoch 127/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7577 - accuracy: 0.8418 - val_loss: 0.6234 - val_accuracy: 0.8565\n","Epoch 128/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6723 - accuracy: 0.8433 - val_loss: 0.6729 - val_accuracy: 0.8484\n","Epoch 129/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5768 - accuracy: 0.8422 - val_loss: 0.6385 - val_accuracy: 0.8487\n","Epoch 130/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5444 - accuracy: 0.8445 - val_loss: 0.6803 - val_accuracy: 0.8507\n","Epoch 131/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7993 - accuracy: 0.8415 - val_loss: 0.6755 - val_accuracy: 0.8545\n","Epoch 132/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5696 - accuracy: 0.8426 - val_loss: 0.6604 - val_accuracy: 0.8513\n","Epoch 133/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5106 - accuracy: 0.8433 - val_loss: 0.6345 - val_accuracy: 0.8467\n","Epoch 134/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5589 - accuracy: 0.8433 - val_loss: 0.6695 - val_accuracy: 0.8431\n","Epoch 135/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6030 - accuracy: 0.8434 - val_loss: 0.6614 - val_accuracy: 0.8475\n","Epoch 136/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6090 - accuracy: 0.8446 - val_loss: 0.6274 - val_accuracy: 0.8451\n","Epoch 137/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5676 - accuracy: 0.8454 - val_loss: 0.6349 - val_accuracy: 0.8471\n","Epoch 138/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6166 - accuracy: 0.8493 - val_loss: 0.6374 - val_accuracy: 0.8558\n","Epoch 139/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5293 - accuracy: 0.8446 - val_loss: 0.6356 - val_accuracy: 0.8484\n","Epoch 140/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5170 - accuracy: 0.8424 - val_loss: 0.6780 - val_accuracy: 0.8469\n","Epoch 141/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5322 - accuracy: 0.8455 - val_loss: 0.6692 - val_accuracy: 0.8429\n","Epoch 142/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6641 - accuracy: 0.8447 - val_loss: 0.6719 - val_accuracy: 0.8482\n","Epoch 143/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5468 - accuracy: 0.8454 - val_loss: 0.6790 - val_accuracy: 0.8473\n","Epoch 144/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6002 - accuracy: 0.8454 - val_loss: 0.7176 - val_accuracy: 0.8540\n","Epoch 145/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5786 - accuracy: 0.8460 - val_loss: 0.6902 - val_accuracy: 0.8533\n","Epoch 146/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5549 - accuracy: 0.8421 - val_loss: 0.6527 - val_accuracy: 0.8518\n","Epoch 147/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5730 - accuracy: 0.8443 - val_loss: 0.6331 - val_accuracy: 0.8529\n","Epoch 148/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6708 - accuracy: 0.8438 - val_loss: 0.6413 - val_accuracy: 0.8509\n","Epoch 149/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5444 - accuracy: 0.8446 - val_loss: 0.6456 - val_accuracy: 0.8525\n","Epoch 150/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6099 - accuracy: 0.8427 - val_loss: 0.6543 - val_accuracy: 0.8435\n","Epoch 151/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7549 - accuracy: 0.8415 - val_loss: 0.6210 - val_accuracy: 0.8516\n","Epoch 152/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5532 - accuracy: 0.8475 - val_loss: 0.6075 - val_accuracy: 0.8496\n","Epoch 153/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5385 - accuracy: 0.8450 - val_loss: 0.6499 - val_accuracy: 0.8455\n","Epoch 154/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6821 - accuracy: 0.8461 - val_loss: 0.6261 - val_accuracy: 0.8536\n","Epoch 155/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5365 - accuracy: 0.8470 - val_loss: 0.6527 - val_accuracy: 0.8498\n","Epoch 156/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5289 - accuracy: 0.8451 - val_loss: 0.6195 - val_accuracy: 0.8446\n","Epoch 157/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.8342 - accuracy: 0.8424 - val_loss: 0.6250 - val_accuracy: 0.8496\n","Epoch 158/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.8051 - accuracy: 0.8457 - val_loss: 0.6194 - val_accuracy: 0.8464\n","Epoch 159/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7072 - accuracy: 0.8443 - val_loss: 0.6188 - val_accuracy: 0.8567\n","Epoch 160/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6876 - accuracy: 0.8458 - val_loss: 0.6506 - val_accuracy: 0.8516\n","Epoch 161/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5230 - accuracy: 0.8476 - val_loss: 0.6429 - val_accuracy: 0.8525\n","Epoch 162/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6858 - accuracy: 0.8444 - val_loss: 0.6491 - val_accuracy: 0.8509\n","Epoch 163/500\n","350/350 [==============================] - 5s 14ms/step - loss: 0.5402 - accuracy: 0.8450 - val_loss: 0.6444 - val_accuracy: 0.8504\n","Epoch 164/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5285 - accuracy: 0.8463 - val_loss: 0.6208 - val_accuracy: 0.8475\n","Epoch 165/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5952 - accuracy: 0.8436 - val_loss: 0.6247 - val_accuracy: 0.8469\n","Epoch 166/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5404 - accuracy: 0.8468 - val_loss: 0.5975 - val_accuracy: 0.8451\n","Epoch 167/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5652 - accuracy: 0.8464 - val_loss: 0.6606 - val_accuracy: 0.8444\n","Epoch 168/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4965 - accuracy: 0.8488 - val_loss: 0.6817 - val_accuracy: 0.8487\n","Epoch 169/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5322 - accuracy: 0.8467 - val_loss: 0.6284 - val_accuracy: 0.8558\n","Epoch 170/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5062 - accuracy: 0.8468 - val_loss: 0.6640 - val_accuracy: 0.8498\n","Epoch 171/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.8008 - accuracy: 0.8454 - val_loss: 0.6772 - val_accuracy: 0.8511\n","Epoch 172/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5285 - accuracy: 0.8454 - val_loss: 0.6243 - val_accuracy: 0.8498\n","Epoch 173/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5932 - accuracy: 0.8462 - val_loss: 0.6496 - val_accuracy: 0.8531\n","Epoch 174/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5411 - accuracy: 0.8477 - val_loss: 0.7084 - val_accuracy: 0.8509\n","Epoch 175/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5327 - accuracy: 0.8454 - val_loss: 0.6565 - val_accuracy: 0.8446\n","Epoch 176/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5646 - accuracy: 0.8461 - val_loss: 0.6374 - val_accuracy: 0.8522\n","Epoch 177/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5869 - accuracy: 0.8466 - val_loss: 0.6827 - val_accuracy: 0.8489\n","Epoch 178/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5262 - accuracy: 0.8467 - val_loss: 0.6349 - val_accuracy: 0.8540\n","Epoch 179/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7042 - accuracy: 0.8451 - val_loss: 0.6045 - val_accuracy: 0.8549\n","Epoch 180/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5603 - accuracy: 0.8509 - val_loss: 0.5920 - val_accuracy: 0.8569\n","Epoch 181/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.8634 - accuracy: 0.8470 - val_loss: 0.6269 - val_accuracy: 0.8498\n","Epoch 182/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5679 - accuracy: 0.8457 - val_loss: 0.6028 - val_accuracy: 0.8518\n","Epoch 183/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6186 - accuracy: 0.8471 - val_loss: 0.6149 - val_accuracy: 0.8520\n","Epoch 184/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5410 - accuracy: 0.8497 - val_loss: 0.6350 - val_accuracy: 0.8527\n","Epoch 185/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5151 - accuracy: 0.8504 - val_loss: 0.6628 - val_accuracy: 0.8556\n","Epoch 186/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6333 - accuracy: 0.8474 - val_loss: 0.6347 - val_accuracy: 0.8525\n","Epoch 187/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5380 - accuracy: 0.8460 - val_loss: 0.6439 - val_accuracy: 0.8446\n","Epoch 188/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5824 - accuracy: 0.8473 - val_loss: 0.6240 - val_accuracy: 0.8556\n","Epoch 189/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5724 - accuracy: 0.8475 - val_loss: 0.5958 - val_accuracy: 0.8513\n","Epoch 190/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4974 - accuracy: 0.8505 - val_loss: 0.6113 - val_accuracy: 0.8525\n","Epoch 191/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5680 - accuracy: 0.8466 - val_loss: 0.6455 - val_accuracy: 0.8393\n","Epoch 192/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5338 - accuracy: 0.8486 - val_loss: 0.5977 - val_accuracy: 0.8562\n","Epoch 193/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7059 - accuracy: 0.8457 - val_loss: 0.6216 - val_accuracy: 0.8540\n","Epoch 194/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5560 - accuracy: 0.8486 - val_loss: 0.6073 - val_accuracy: 0.8527\n","Epoch 195/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6714 - accuracy: 0.8431 - val_loss: 0.5953 - val_accuracy: 0.8529\n","Epoch 196/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5794 - accuracy: 0.8497 - val_loss: 0.6300 - val_accuracy: 0.8520\n","Epoch 197/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5384 - accuracy: 0.8457 - val_loss: 0.5922 - val_accuracy: 0.8538\n","Epoch 198/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5307 - accuracy: 0.8500 - val_loss: 0.6057 - val_accuracy: 0.8522\n","Epoch 199/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5163 - accuracy: 0.8469 - val_loss: 0.5938 - val_accuracy: 0.8538\n","Epoch 200/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5225 - accuracy: 0.8486 - val_loss: 0.6202 - val_accuracy: 0.8473\n","Epoch 201/500\n","[INFO] lr is  ...  1.0000000474974514e-05\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5285 - accuracy: 0.8503 - val_loss: 0.6148 - val_accuracy: 0.8518\n","Epoch 202/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4998 - accuracy: 0.8523 - val_loss: 0.5983 - val_accuracy: 0.8518\n","Epoch 203/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4931 - accuracy: 0.8514 - val_loss: 0.5874 - val_accuracy: 0.8520\n","Epoch 204/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4944 - accuracy: 0.8540 - val_loss: 0.6172 - val_accuracy: 0.8504\n","Epoch 205/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5866 - accuracy: 0.8505 - val_loss: 0.6093 - val_accuracy: 0.8513\n","Epoch 206/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5473 - accuracy: 0.8490 - val_loss: 0.6151 - val_accuracy: 0.8516\n","Epoch 207/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6034 - accuracy: 0.8526 - val_loss: 0.6163 - val_accuracy: 0.8520\n","Epoch 208/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5770 - accuracy: 0.8514 - val_loss: 0.5958 - val_accuracy: 0.8531\n","Epoch 209/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6144 - accuracy: 0.8501 - val_loss: 0.5956 - val_accuracy: 0.8533\n","Epoch 210/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7856 - accuracy: 0.8494 - val_loss: 0.6251 - val_accuracy: 0.8527\n","Epoch 211/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5549 - accuracy: 0.8489 - val_loss: 0.6001 - val_accuracy: 0.8531\n","Epoch 212/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4850 - accuracy: 0.8521 - val_loss: 0.6137 - val_accuracy: 0.8513\n","Epoch 213/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5822 - accuracy: 0.8541 - val_loss: 0.6024 - val_accuracy: 0.8525\n","Epoch 214/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5255 - accuracy: 0.8514 - val_loss: 0.5950 - val_accuracy: 0.8502\n","Epoch 215/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5731 - accuracy: 0.8496 - val_loss: 0.6067 - val_accuracy: 0.8525\n","Epoch 216/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5777 - accuracy: 0.8498 - val_loss: 0.6058 - val_accuracy: 0.8527\n","Epoch 217/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5370 - accuracy: 0.8530 - val_loss: 0.6159 - val_accuracy: 0.8533\n","Epoch 218/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4831 - accuracy: 0.8512 - val_loss: 0.6003 - val_accuracy: 0.8549\n","Epoch 219/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5387 - accuracy: 0.8519 - val_loss: 0.6233 - val_accuracy: 0.8525\n","Epoch 220/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5918 - accuracy: 0.8510 - val_loss: 0.6139 - val_accuracy: 0.8531\n","Epoch 221/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5273 - accuracy: 0.8506 - val_loss: 0.5940 - val_accuracy: 0.8513\n","Epoch 222/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5659 - accuracy: 0.8545 - val_loss: 0.6233 - val_accuracy: 0.8533\n","Epoch 223/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6606 - accuracy: 0.8488 - val_loss: 0.5958 - val_accuracy: 0.8533\n","Epoch 224/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5098 - accuracy: 0.8522 - val_loss: 0.6190 - val_accuracy: 0.8551\n","Epoch 225/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5404 - accuracy: 0.8524 - val_loss: 0.6166 - val_accuracy: 0.8540\n","Epoch 226/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5030 - accuracy: 0.8533 - val_loss: 0.6029 - val_accuracy: 0.8520\n","Epoch 227/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5079 - accuracy: 0.8504 - val_loss: 0.6150 - val_accuracy: 0.8556\n","Epoch 228/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5652 - accuracy: 0.8507 - val_loss: 0.6167 - val_accuracy: 0.8536\n","Epoch 229/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5513 - accuracy: 0.8534 - val_loss: 0.6107 - val_accuracy: 0.8547\n","Epoch 230/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4898 - accuracy: 0.8513 - val_loss: 0.5924 - val_accuracy: 0.8529\n","Epoch 231/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5448 - accuracy: 0.8493 - val_loss: 0.6168 - val_accuracy: 0.8536\n","Epoch 232/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5032 - accuracy: 0.8519 - val_loss: 0.6317 - val_accuracy: 0.8513\n","Epoch 233/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5325 - accuracy: 0.8512 - val_loss: 0.6165 - val_accuracy: 0.8540\n","Epoch 234/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5670 - accuracy: 0.8510 - val_loss: 0.6241 - val_accuracy: 0.8558\n","Epoch 235/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5452 - accuracy: 0.8547 - val_loss: 0.6109 - val_accuracy: 0.8547\n","Epoch 236/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6304 - accuracy: 0.8514 - val_loss: 0.6062 - val_accuracy: 0.8536\n","Epoch 237/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5185 - accuracy: 0.8507 - val_loss: 0.6176 - val_accuracy: 0.8533\n","Epoch 238/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7698 - accuracy: 0.8492 - val_loss: 0.6025 - val_accuracy: 0.8551\n","Epoch 239/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7120 - accuracy: 0.8514 - val_loss: 0.6086 - val_accuracy: 0.8542\n","Epoch 240/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5101 - accuracy: 0.8497 - val_loss: 0.6100 - val_accuracy: 0.8509\n","Epoch 241/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6061 - accuracy: 0.8513 - val_loss: 0.6304 - val_accuracy: 0.8513\n","Epoch 242/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5289 - accuracy: 0.8504 - val_loss: 0.6036 - val_accuracy: 0.8511\n","Epoch 243/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.8208 - accuracy: 0.8527 - val_loss: 0.6142 - val_accuracy: 0.8525\n","Epoch 244/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5154 - accuracy: 0.8526 - val_loss: 0.5992 - val_accuracy: 0.8520\n","Epoch 245/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7835 - accuracy: 0.8509 - val_loss: 0.6044 - val_accuracy: 0.8518\n","Epoch 246/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5157 - accuracy: 0.8505 - val_loss: 0.6324 - val_accuracy: 0.8533\n","Epoch 247/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6405 - accuracy: 0.8513 - val_loss: 0.6204 - val_accuracy: 0.8527\n","Epoch 248/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5143 - accuracy: 0.8537 - val_loss: 0.6276 - val_accuracy: 0.8545\n","Epoch 249/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5064 - accuracy: 0.8498 - val_loss: 0.6362 - val_accuracy: 0.8529\n","Epoch 250/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5229 - accuracy: 0.8536 - val_loss: 0.6243 - val_accuracy: 0.8533\n","Epoch 251/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4999 - accuracy: 0.8522 - val_loss: 0.6260 - val_accuracy: 0.8531\n","Epoch 252/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5907 - accuracy: 0.8519 - val_loss: 0.6205 - val_accuracy: 0.8529\n","Epoch 253/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4857 - accuracy: 0.8514 - val_loss: 0.6243 - val_accuracy: 0.8529\n","Epoch 254/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7629 - accuracy: 0.8484 - val_loss: 0.6324 - val_accuracy: 0.8545\n","Epoch 255/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5958 - accuracy: 0.8511 - val_loss: 0.6255 - val_accuracy: 0.8538\n","Epoch 256/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5758 - accuracy: 0.8522 - val_loss: 0.6242 - val_accuracy: 0.8531\n","Epoch 257/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7185 - accuracy: 0.8498 - val_loss: 0.6177 - val_accuracy: 0.8525\n","Epoch 258/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5968 - accuracy: 0.8501 - val_loss: 0.6276 - val_accuracy: 0.8531\n","Epoch 259/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5720 - accuracy: 0.8523 - val_loss: 0.6197 - val_accuracy: 0.8533\n","Epoch 260/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5083 - accuracy: 0.8514 - val_loss: 0.6383 - val_accuracy: 0.8522\n","Epoch 261/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5497 - accuracy: 0.8519 - val_loss: 0.6329 - val_accuracy: 0.8531\n","Epoch 262/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5359 - accuracy: 0.8491 - val_loss: 0.6088 - val_accuracy: 0.8527\n","Epoch 263/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5747 - accuracy: 0.8556 - val_loss: 0.6142 - val_accuracy: 0.8527\n","Epoch 264/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5188 - accuracy: 0.8507 - val_loss: 0.6153 - val_accuracy: 0.8531\n","Epoch 265/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5075 - accuracy: 0.8534 - val_loss: 0.6133 - val_accuracy: 0.8558\n","Epoch 266/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4896 - accuracy: 0.8526 - val_loss: 0.6182 - val_accuracy: 0.8533\n","Epoch 267/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5069 - accuracy: 0.8517 - val_loss: 0.6334 - val_accuracy: 0.8538\n","Epoch 268/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5253 - accuracy: 0.8509 - val_loss: 0.6174 - val_accuracy: 0.8511\n","Epoch 269/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6732 - accuracy: 0.8522 - val_loss: 0.6290 - val_accuracy: 0.8533\n","Epoch 270/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6119 - accuracy: 0.8514 - val_loss: 0.6303 - val_accuracy: 0.8538\n","Epoch 271/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6144 - accuracy: 0.8517 - val_loss: 0.6180 - val_accuracy: 0.8516\n","Epoch 272/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5011 - accuracy: 0.8546 - val_loss: 0.6239 - val_accuracy: 0.8525\n","Epoch 273/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5767 - accuracy: 0.8534 - val_loss: 0.6396 - val_accuracy: 0.8525\n","Epoch 274/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5268 - accuracy: 0.8525 - val_loss: 0.6439 - val_accuracy: 0.8502\n","Epoch 275/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6331 - accuracy: 0.8488 - val_loss: 0.6281 - val_accuracy: 0.8529\n","Epoch 276/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5514 - accuracy: 0.8527 - val_loss: 0.6339 - val_accuracy: 0.8536\n","Epoch 277/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5189 - accuracy: 0.8502 - val_loss: 0.6233 - val_accuracy: 0.8538\n","Epoch 278/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4949 - accuracy: 0.8526 - val_loss: 0.6373 - val_accuracy: 0.8533\n","Epoch 279/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5322 - accuracy: 0.8521 - val_loss: 0.6328 - val_accuracy: 0.8531\n","Epoch 280/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5335 - accuracy: 0.8499 - val_loss: 0.6222 - val_accuracy: 0.8533\n","Epoch 281/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5449 - accuracy: 0.8526 - val_loss: 0.6183 - val_accuracy: 0.8538\n","Epoch 282/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5708 - accuracy: 0.8509 - val_loss: 0.6301 - val_accuracy: 0.8498\n","Epoch 283/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5480 - accuracy: 0.8535 - val_loss: 0.6109 - val_accuracy: 0.8502\n","Epoch 284/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5372 - accuracy: 0.8516 - val_loss: 0.6211 - val_accuracy: 0.8525\n","Epoch 285/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4957 - accuracy: 0.8509 - val_loss: 0.6103 - val_accuracy: 0.8507\n","Epoch 286/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5120 - accuracy: 0.8501 - val_loss: 0.6286 - val_accuracy: 0.8518\n","Epoch 287/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5036 - accuracy: 0.8514 - val_loss: 0.6111 - val_accuracy: 0.8513\n","Epoch 288/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4795 - accuracy: 0.8535 - val_loss: 0.6210 - val_accuracy: 0.8522\n","Epoch 289/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5007 - accuracy: 0.8523 - val_loss: 0.6154 - val_accuracy: 0.8542\n","Epoch 290/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5084 - accuracy: 0.8532 - val_loss: 0.6254 - val_accuracy: 0.8545\n","Epoch 291/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5461 - accuracy: 0.8522 - val_loss: 0.6135 - val_accuracy: 0.8518\n","Epoch 292/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5240 - accuracy: 0.8518 - val_loss: 0.6107 - val_accuracy: 0.8518\n","Epoch 293/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5142 - accuracy: 0.8512 - val_loss: 0.6328 - val_accuracy: 0.8545\n","Epoch 294/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4757 - accuracy: 0.8530 - val_loss: 0.6334 - val_accuracy: 0.8527\n","Epoch 295/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6592 - accuracy: 0.8522 - val_loss: 0.6121 - val_accuracy: 0.8536\n","Epoch 296/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5619 - accuracy: 0.8511 - val_loss: 0.6301 - val_accuracy: 0.8549\n","Epoch 297/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.8080 - accuracy: 0.8510 - val_loss: 0.6231 - val_accuracy: 0.8513\n","Epoch 298/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6995 - accuracy: 0.8521 - val_loss: 0.6065 - val_accuracy: 0.8516\n","Epoch 299/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5836 - accuracy: 0.8530 - val_loss: 0.6217 - val_accuracy: 0.8551\n","Epoch 300/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7507 - accuracy: 0.8501 - val_loss: 0.6107 - val_accuracy: 0.8531\n","Epoch 301/500\n","[INFO] lr is  ...  1.0000000656873453e-06\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5498 - accuracy: 0.8545 - val_loss: 0.6152 - val_accuracy: 0.8538\n","Epoch 302/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7256 - accuracy: 0.8558 - val_loss: 0.6296 - val_accuracy: 0.8529\n","Epoch 303/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5365 - accuracy: 0.8522 - val_loss: 0.6203 - val_accuracy: 0.8545\n","Epoch 304/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5066 - accuracy: 0.8541 - val_loss: 0.6127 - val_accuracy: 0.8533\n","Epoch 305/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5218 - accuracy: 0.8535 - val_loss: 0.6219 - val_accuracy: 0.8545\n","Epoch 306/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5116 - accuracy: 0.8509 - val_loss: 0.6166 - val_accuracy: 0.8533\n","Epoch 307/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5088 - accuracy: 0.8536 - val_loss: 0.6087 - val_accuracy: 0.8536\n","Epoch 308/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5510 - accuracy: 0.8519 - val_loss: 0.6200 - val_accuracy: 0.8536\n","Epoch 309/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5172 - accuracy: 0.8520 - val_loss: 0.6078 - val_accuracy: 0.8542\n","Epoch 310/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5366 - accuracy: 0.8515 - val_loss: 0.6194 - val_accuracy: 0.8536\n","Epoch 311/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5486 - accuracy: 0.8535 - val_loss: 0.6293 - val_accuracy: 0.8538\n","Epoch 312/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5350 - accuracy: 0.8533 - val_loss: 0.6155 - val_accuracy: 0.8547\n","Epoch 313/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6122 - accuracy: 0.8497 - val_loss: 0.6098 - val_accuracy: 0.8551\n","Epoch 314/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5172 - accuracy: 0.8515 - val_loss: 0.6289 - val_accuracy: 0.8540\n","Epoch 315/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5643 - accuracy: 0.8541 - val_loss: 0.6006 - val_accuracy: 0.8540\n","Epoch 316/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5779 - accuracy: 0.8541 - val_loss: 0.6021 - val_accuracy: 0.8540\n","Epoch 317/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5195 - accuracy: 0.8518 - val_loss: 0.6011 - val_accuracy: 0.8527\n","Epoch 318/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5768 - accuracy: 0.8514 - val_loss: 0.6248 - val_accuracy: 0.8529\n","Epoch 319/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6841 - accuracy: 0.8523 - val_loss: 0.6077 - val_accuracy: 0.8522\n","Epoch 320/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5741 - accuracy: 0.8526 - val_loss: 0.6064 - val_accuracy: 0.8529\n","Epoch 321/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6210 - accuracy: 0.8522 - val_loss: 0.6128 - val_accuracy: 0.8533\n","Epoch 322/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5480 - accuracy: 0.8549 - val_loss: 0.6276 - val_accuracy: 0.8545\n","Epoch 323/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5903 - accuracy: 0.8526 - val_loss: 0.6166 - val_accuracy: 0.8536\n","Epoch 324/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5320 - accuracy: 0.8522 - val_loss: 0.6061 - val_accuracy: 0.8511\n","Epoch 325/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5674 - accuracy: 0.8555 - val_loss: 0.6117 - val_accuracy: 0.8538\n","Epoch 326/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5181 - accuracy: 0.8540 - val_loss: 0.6290 - val_accuracy: 0.8525\n","Epoch 327/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4933 - accuracy: 0.8534 - val_loss: 0.6215 - val_accuracy: 0.8551\n","Epoch 328/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5366 - accuracy: 0.8500 - val_loss: 0.6022 - val_accuracy: 0.8538\n","Epoch 329/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5772 - accuracy: 0.8540 - val_loss: 0.6191 - val_accuracy: 0.8542\n","Epoch 330/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5383 - accuracy: 0.8509 - val_loss: 0.6249 - val_accuracy: 0.8538\n","Epoch 331/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4938 - accuracy: 0.8508 - val_loss: 0.6323 - val_accuracy: 0.8527\n","Epoch 332/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4922 - accuracy: 0.8534 - val_loss: 0.6172 - val_accuracy: 0.8531\n","Epoch 333/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4777 - accuracy: 0.8514 - val_loss: 0.6254 - val_accuracy: 0.8536\n","Epoch 334/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4863 - accuracy: 0.8547 - val_loss: 0.6131 - val_accuracy: 0.8536\n","Epoch 335/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5987 - accuracy: 0.8527 - val_loss: 0.6304 - val_accuracy: 0.8536\n","Epoch 336/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6011 - accuracy: 0.8538 - val_loss: 0.6263 - val_accuracy: 0.8542\n","Epoch 337/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5253 - accuracy: 0.8552 - val_loss: 0.6114 - val_accuracy: 0.8545\n","Epoch 338/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5244 - accuracy: 0.8541 - val_loss: 0.6195 - val_accuracy: 0.8531\n","Epoch 339/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5051 - accuracy: 0.8517 - val_loss: 0.6132 - val_accuracy: 0.8549\n","Epoch 340/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6482 - accuracy: 0.8508 - val_loss: 0.6245 - val_accuracy: 0.8540\n","Epoch 341/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6828 - accuracy: 0.8499 - val_loss: 0.6184 - val_accuracy: 0.8533\n","Epoch 342/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5549 - accuracy: 0.8540 - val_loss: 0.6281 - val_accuracy: 0.8533\n","Epoch 343/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6829 - accuracy: 0.8490 - val_loss: 0.6224 - val_accuracy: 0.8540\n","Epoch 344/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5100 - accuracy: 0.8524 - val_loss: 0.6059 - val_accuracy: 0.8531\n","Epoch 345/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5470 - accuracy: 0.8505 - val_loss: 0.6192 - val_accuracy: 0.8536\n","Epoch 346/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5306 - accuracy: 0.8531 - val_loss: 0.6141 - val_accuracy: 0.8536\n","Epoch 347/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5407 - accuracy: 0.8535 - val_loss: 0.6317 - val_accuracy: 0.8527\n","Epoch 348/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5534 - accuracy: 0.8530 - val_loss: 0.6327 - val_accuracy: 0.8545\n","Epoch 349/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5026 - accuracy: 0.8539 - val_loss: 0.6293 - val_accuracy: 0.8529\n","Epoch 350/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7108 - accuracy: 0.8533 - val_loss: 0.6121 - val_accuracy: 0.8518\n","Epoch 351/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6540 - accuracy: 0.8500 - val_loss: 0.6069 - val_accuracy: 0.8522\n","Epoch 352/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4933 - accuracy: 0.8505 - val_loss: 0.6224 - val_accuracy: 0.8536\n","Epoch 353/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7719 - accuracy: 0.8514 - val_loss: 0.6272 - val_accuracy: 0.8533\n","Epoch 354/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5003 - accuracy: 0.8534 - val_loss: 0.6279 - val_accuracy: 0.8536\n","Epoch 355/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5542 - accuracy: 0.8522 - val_loss: 0.6130 - val_accuracy: 0.8538\n","Epoch 356/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5283 - accuracy: 0.8497 - val_loss: 0.6313 - val_accuracy: 0.8533\n","Epoch 357/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5372 - accuracy: 0.8518 - val_loss: 0.6239 - val_accuracy: 0.8542\n","Epoch 358/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5222 - accuracy: 0.8515 - val_loss: 0.6287 - val_accuracy: 0.8538\n","Epoch 359/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5175 - accuracy: 0.8525 - val_loss: 0.6180 - val_accuracy: 0.8533\n","Epoch 360/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5405 - accuracy: 0.8525 - val_loss: 0.6201 - val_accuracy: 0.8538\n","Epoch 361/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5056 - accuracy: 0.8523 - val_loss: 0.6278 - val_accuracy: 0.8542\n","Epoch 362/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5586 - accuracy: 0.8548 - val_loss: 0.6222 - val_accuracy: 0.8529\n","Epoch 363/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5147 - accuracy: 0.8517 - val_loss: 0.6248 - val_accuracy: 0.8538\n","Epoch 364/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4828 - accuracy: 0.8514 - val_loss: 0.6202 - val_accuracy: 0.8533\n","Epoch 365/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5206 - accuracy: 0.8525 - val_loss: 0.6287 - val_accuracy: 0.8527\n","Epoch 366/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5896 - accuracy: 0.8525 - val_loss: 0.6230 - val_accuracy: 0.8540\n","Epoch 367/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5633 - accuracy: 0.8540 - val_loss: 0.6330 - val_accuracy: 0.8533\n","Epoch 368/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4972 - accuracy: 0.8531 - val_loss: 0.6120 - val_accuracy: 0.8547\n","Epoch 369/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4777 - accuracy: 0.8550 - val_loss: 0.6244 - val_accuracy: 0.8545\n","Epoch 370/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5476 - accuracy: 0.8509 - val_loss: 0.6172 - val_accuracy: 0.8533\n","Epoch 371/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5775 - accuracy: 0.8514 - val_loss: 0.6262 - val_accuracy: 0.8522\n","Epoch 372/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5089 - accuracy: 0.8525 - val_loss: 0.6042 - val_accuracy: 0.8540\n","Epoch 373/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5191 - accuracy: 0.8522 - val_loss: 0.6253 - val_accuracy: 0.8540\n","Epoch 374/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5762 - accuracy: 0.8511 - val_loss: 0.6232 - val_accuracy: 0.8533\n","Epoch 375/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6373 - accuracy: 0.8497 - val_loss: 0.6368 - val_accuracy: 0.8531\n","Epoch 376/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5250 - accuracy: 0.8552 - val_loss: 0.6127 - val_accuracy: 0.8542\n","Epoch 377/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5312 - accuracy: 0.8522 - val_loss: 0.6184 - val_accuracy: 0.8533\n","Epoch 378/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7623 - accuracy: 0.8506 - val_loss: 0.6263 - val_accuracy: 0.8529\n","Epoch 379/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5626 - accuracy: 0.8529 - val_loss: 0.6057 - val_accuracy: 0.8518\n","Epoch 380/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5701 - accuracy: 0.8540 - val_loss: 0.6284 - val_accuracy: 0.8536\n","Epoch 381/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6760 - accuracy: 0.8517 - val_loss: 0.6137 - val_accuracy: 0.8529\n","Epoch 382/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5288 - accuracy: 0.8522 - val_loss: 0.6318 - val_accuracy: 0.8529\n","Epoch 383/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5236 - accuracy: 0.8523 - val_loss: 0.6255 - val_accuracy: 0.8536\n","Epoch 384/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4965 - accuracy: 0.8540 - val_loss: 0.6247 - val_accuracy: 0.8538\n","Epoch 385/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5189 - accuracy: 0.8513 - val_loss: 0.6270 - val_accuracy: 0.8538\n","Epoch 386/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.7391 - accuracy: 0.8518 - val_loss: 0.6077 - val_accuracy: 0.8542\n","Epoch 387/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.6101 - accuracy: 0.8513 - val_loss: 0.6163 - val_accuracy: 0.8545\n","Epoch 388/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5193 - accuracy: 0.8517 - val_loss: 0.6228 - val_accuracy: 0.8545\n","Epoch 389/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.4948 - accuracy: 0.8528 - val_loss: 0.6141 - val_accuracy: 0.8545\n","Epoch 390/500\n","350/350 [==============================] - 5s 13ms/step - loss: 0.5100 - accuracy: 0.8518 - val_loss: 0.6117 - val_accuracy: 0.8536\n","Epoch 391/500\n","304/350 [=========================>....] - ETA: 0s - loss: 0.4985 - accuracy: 0.8520"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J7qblXbvQZa-"},"source":["# Model Summary\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o8EYRdL5Qqzn"},"source":["# Prediction of Model\n","pred_Y = model.predict(Test_X)\n","pred_Y_N = np.argmax(pred_Y, axis=1)\n","Pred_Y = enc.fit_transform(pred_Y_N.reshape(-1, 1)).toarray()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KDdUnweBQsGT"},"source":["# Apply One Hot Encoding Transform\n","Pred_Y_N = enc.inverse_transform(Pred_Y)\n","Test_Y_N = enc.inverse_transform(Test_Y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yR7_zj_OQq2r"},"source":["print(confusion_matrix(Test_Y_N, Pred_Y_N))\n","print(classification_report(Test_Y_N, Pred_Y_N))\n","print(accuracy_score(Test_Y_N, Pred_Y_N))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r3MZJIKGQq5p"},"source":["# Plt Confusion Matrix\n","LABELS = ['bike','bus','car','train','walk']\n","cm = confusion_matrix(Test_Y_N, Pred_Y_N)\n","bg_color = (0.88,0.85,0.95)\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import seaborn as sn\n","plt.figure(figsize=(15,10))\n","sn.heatmap(cm,xticklabels=LABELS, yticklabels=LABELS,annot=True, fmt=\"d\", cmap='jet', annot_kws={'size':15})\n","plt.title('Confusion Matrix', fontsize = 20)\n","plt.xticks(fontsize=16)\n","plt.yticks(fontsize=16)\n","plt.xlabel('Predicted', fontsize = 16)\n","plt.ylabel('True', fontsize = 16)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tUimvpovQ7eW"},"source":["# Summarize History For Accuracy\n","plt.figure(figsize=(10, 7))\n","plt.xticks(fontsize=16)\n","plt.yticks(fontsize=16)\n","plt.plot(hist.history['accuracy'])\n","plt.plot(hist.history['val_accuracy'])\n","plt.title('Model Accuracy', fontsize = 20)\n","plt.ylabel('Accuracy', fontsize = 16)\n","plt.xlabel('Epoch', fontsize = 16)\n","plt.legend(['Train', 'Test'], loc='upper left', fontsize = 16)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LNATHP5AQ7hH"},"source":["# Summarize History For Loss\n","plt.figure(figsize=(10, 7))\n","plt.xticks(fontsize=16)\n","plt.yticks(fontsize=16)\n","plt.plot(hist.history['loss'])\n","plt.plot(hist.history['val_loss'])\n","plt.title('Model Loss', fontsize = 20)\n","plt.ylabel('Loss', fontsize = 16)\n","plt.xlabel('Epoch', fontsize = 16)\n","plt.legend(['train', 'test'], loc='upper left', fontsize = 16)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WbbgJMiVQ7pW"},"source":[""],"execution_count":null,"outputs":[]}]}